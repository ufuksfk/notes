---
title: "Redefine Safety and AI with xLSTM and SLAM"
draft: false
publisher: "[[Industrial AI Podcast]]"
published_date: 2024-11-21
tags:
  - "sustainability"
---


## Highlights
* [[2024-11-21]] 17:39  Stefan Miltz. He's the founder, managing director and also the head of R and D at Spleen Lab.

* [[2024-11-21]] 18:42  The neural network based approach to safety has not yet been approved for safety for safety requirements.

* [[2024-11-22]] 08:52  And this is the nature of how the current regulations are designed. Like what I told you before, right? The ISO 262 or industry, it's the IEC 61508. They really want some deterministic tree where all probability states are defined and everything that could happen with the system will be described in the safety mitigation.

* [[2024-11-22]] 08:52  And if it comes down to a neural network, you typically have so many parameters. So you all know these large language models, right? Even 70 billion parameters of a medium sized large language model is almost impossible to tell in terms of safety mitigation what could happen if you try out all permutations. So at the end it's a statistical model.

